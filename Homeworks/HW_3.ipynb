{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996f0460-1389-4deb-b05a-3948646fada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK #3 - A total of 40 objects were kept for further analysis\n",
      "querying sdss database for all objects, sleeping for 1 second after each query, be patient...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 215\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m#TJ these tables are now only the relevent objects that will be used for further analysis\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTASK #3 - A total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(rel_FIRST_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m objects were kept for further analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#TJ print total objects that are kept\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m rel_sweep_data \u001b[38;5;241m=\u001b[39m add_sdss_u_and_i_mag_columns(rel_sweep_data) \u001b[38;5;66;03m#TJ query sdss database for each of these objects\u001b[39;00m\n\u001b[1;32m    217\u001b[0m nan_count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39misnan(rel_sweep_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu_mag\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;66;03m#TJ count how many nan values are in the set\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m#TJ the total length, minus number of nans is the number of successful queries from SDSS\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 162\u001b[0m, in \u001b[0;36madd_sdss_u_and_i_mag_columns\u001b[0;34m(table, sdss_path)\u001b[0m\n\u001b[1;32m    159\u001b[0m ra, dec \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRA\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#TJ assign ra and dec values for query\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m#TJ run the required sdss script and capture the output as a text string, strip off any extraneous white spaces\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m output \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output(\n\u001b[1;32m    163\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msdss_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mra\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m#TJ runs the script as a subprocess\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m#TJ makes output a string, rather than bytes\u001b[39;00m\n\u001b[1;32m    165\u001b[0m )\u001b[38;5;241m.\u001b[39mstrip()  \u001b[38;5;66;03m#TJ strips off any leading/trailing whitespace\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo objects have been found\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;66;03m#TJ use my ONE extra if statement to leave value as nan if there are no objects found\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Anaconda2024/lib/python3.11/subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    464\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run(\u001b[38;5;241m*\u001b[39mpopenargs, stdout\u001b[38;5;241m=\u001b[39mPIPE, timeout\u001b[38;5;241m=\u001b[39mtimeout, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    467\u001b[0m            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m/usr/local/Anaconda2024/lib/python3.11/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/local/Anaconda2024/lib/python3.11/subprocess.py:1196\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stdin_write(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout:\n\u001b[0;32m-> 1196\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()#TJ get exact start time (for computing total execution time)\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) #TJ change directory to include the entire ASTRO5160 directory\n",
    "from astropy.table import Table, vstack, Column, Row\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import argparse\n",
    "from Week8.Class16_notebook import *\n",
    "\n",
    "\n",
    "def is_it_in(objs, box):\n",
    "    \"\"\"Determine which of an array of objects are inside an RA, Dec box. Trimmed version of ADAM's function with inclusive boundaries\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    objs :  type = astropy.table or list - array of objects, must include columns titled \"RA\" and \"DEC\"\n",
    "    box :  type = list - list of floats corresponding to the boundaries of the box\n",
    "                *must be in format [ra_min, ra_max, dec_min, dec_max] with boundaries in degrees*\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    original objs replaced with boolean values stating whether they are in the box (True) or not (False)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    ramin, ramax, decmin, decmax = box\n",
    "\n",
    "    ii = ((objs[\"RA\"] >= ramin) & (objs[\"RA\"] <= ramax) & (objs[\"DEC\"] >= decmin) & (objs[\"DEC\"] <= decmax))\n",
    "\n",
    "    return ii #TJ return true or false array\n",
    "\n",
    "def read_partial_fits(filepath, kept_column_names):\n",
    "    '''read in table and only save necessary columns this saves memory and time with further manipulations compared to saving EVERY column\n",
    "    -------------\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    filepath :  type = str - string representing path to .fits files you want to read in\n",
    "    kept_column_names :  type = list - list of strings corresponding to which columns need to be read in. All other columns are ignored\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    table with only the columns that we wanted to keep\n",
    "    '''\n",
    "    \n",
    "    with fits.open(filepath) as hdul:\n",
    "        data = hdul[1].data  #TJ read in all data\n",
    "        filtered_data = {col: data[col] for col in kept_column_names} #TJ filter data to only keep necessary columns\n",
    "        return Table(filtered_data)\n",
    "\n",
    "\n",
    "\n",
    "def add_mag_column(original_table, fluxes):\n",
    "    '''Add one new column in table for every column with name in fluxes (example: FLUX_x). New column will be named \"x_mag\".\n",
    "    *Assumes fluxes are given in nanomaggy\n",
    "    -------------\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    table :  type = astropy.table - table with at least one column name in \"fluxes\"\n",
    "    fluxes : type = list - list of strings corresponding to which columns of fluxes you want to add a corresponding magnitude column\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    Original table, with new columns for magnitudes\n",
    "    '''\n",
    "\n",
    "    for flux_col in fluxes:\n",
    "        band = flux_col.split('_')[1] #TJ extract column name, \"FLUX_R\" will have the \"R\" pulled out and used to name new column \"R_mag\"\n",
    "        new_col_name = f\"{band}_mag\"  #TJ define new column e.g., 'G_mag' for original \"FLUX_G\"\n",
    "\n",
    "        original_table[new_col_name] = 22.5 - 2.5*np.log10(original_table[flux_col]) #TJ convert flux to magnitude\n",
    "    return original_table\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cross_match(match_all_these, find_matches_from_here, max_sep=1/3600):\n",
    "    '''find objects in the find_matches_from_here table that are the closest RA,DEC from the objects in the match_all_these table\n",
    "\n",
    "    -------------\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    match_all_these :  type = astropy.table - table with columns for \"RA\" and \"DEC\"\n",
    "    find_matches_from_here :  type = astropy.table - table with columns for \"RA\" and \"DEC\"\n",
    "    max_sep (optional, defaults to 1/3600) : type = float - fail to match objects if no object is closer than this many degrees away from it                  \n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    Table with only rows selected from the match_all_these table that found matches in the find_matches_from_here table\n",
    "    Table from the find_matches_from_here table that are the valid matches to entries in the match_all_these table\n",
    "    '''\n",
    "    #TJ create skycoord object for all objects in survey table, convert to cartesian for accurate ckd searching\n",
    "    #TJ ckdtree uses euclidiean distance formula, so leaving it in ra and dec would distort near poles\n",
    "    survey_coords = SkyCoord(find_matches_from_here['RA'], find_matches_from_here['DEC'], unit=u.deg)\n",
    "    survey_xyz = np.vstack(survey_coords.cartesian.xyz).T \n",
    "    \n",
    "    #TJ create skycoord object for all objects in observation table, convert to cartesian to remove dimensional distortion for cdk tree structuring\n",
    "    obs_coords = SkyCoord(match_all_these['RA'], match_all_these['DEC'], unit=u.deg)\n",
    "    obs_xyz = np.vstack(obs_coords.cartesian.xyz).T\n",
    "    tree = cKDTree(survey_xyz) #TJ build ckd tree for efficient searching\n",
    "\n",
    "    #TJ query the tree for the nearest neighbor of each object in match_all_these table\n",
    "    _, matched_indices = tree.query(obs_xyz) #TJ first output is the matched entry's euclidean distance from source, not easy to convert to deg\n",
    "    \n",
    "    separations = obs_coords.separation(survey_coords[matched_indices]).deg  #TJ calculate separation from each \"closest match\" object\n",
    "\n",
    "    #TJ apply filters requested in HW3 prompts\n",
    "    valid_matches = (separations < max_sep) & \\\n",
    "                    (find_matches_from_here['R_mag'][matched_indices] <= 22) & \\\n",
    "                    ((find_matches_from_here['W1_mag'][matched_indices] - find_matches_from_here['W2_mag'][matched_indices]) > 0.5)\n",
    "\n",
    "    #TJ extract the objects that satisfy all the above constraints, return BOTH tables' filtered rows\n",
    "    filtered_match_all_these = match_all_these[valid_matches]\n",
    "    filtered_matches_table = find_matches_from_here[matched_indices[valid_matches]]\n",
    "\n",
    "\n",
    "    return filtered_match_all_these, filtered_matches_table\n",
    "\n",
    "\n",
    "def add_sdss_u_and_i_mag_columns(table, sdss_path='/d/scratch/ASTR5160/week8/sdssDR9query.py'):\n",
    "    '''takes a table with columns for \"RA\" and \"DEC\", and adds new columns for u_mag and i_mag, filled with data from sdss database\n",
    "\n",
    "    *NOTE* This function uses a slow process for querying objects, it is generally recomended to use sdss_query() function from\n",
    "    random_functions.py, as that one will query the first 60 objects as quickly as possible, and will always query the full maximum of \n",
    "    60 objects per minute. This function sleeps for 1 second every query and therefore takes longer than 1 minute to query 60 objects.\n",
    "    -------------\n",
    "\n",
    "    Reequires access to 'sdssDR9query.py' via path given as optional argument\n",
    "    -------------\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    table :  type = astropy.table - table with columns for \"RA\" and \"DEC\", case-sensitive\n",
    "    sdss_path (optional, defaults to '/d/scratch/ASTR5160/week8/sdssDR9query.py') : type = str - path to sdss_query script\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    original table, now with columns for u_mag and i_mag (value will be nan if no object was found in sdss query (tolerance of 1.2\")\n",
    "    '''\n",
    "    \n",
    "    #TJ add columns for SDSS query results\n",
    "    table.add_column(Column(name='u_mag', data=np.nan * len(table)))\n",
    "    table.add_column(Column(name='i_mag', data=np.nan * len(table)))\n",
    "    print('querying sdss database for all objects, sleeping for 1 second after each query, be patient...')\n",
    "    for row in table:\n",
    "        ra, dec = row['RA'], row['DEC'] #TJ assign ra and dec values for query\n",
    "        \n",
    "        #TJ run the required sdss script and capture the output as a text string, strip off any extraneous white spaces\n",
    "        output = subprocess.check_output(\n",
    "            ['python', f'{sdss_path}', f'{ra}', f'{dec}'], #TJ runs the script as a subprocess\n",
    "            text=True  #TJ makes output a string, rather than bytes\n",
    "        ).strip()  #TJ strips off any leading/trailing whitespace\n",
    "        if output == 'No objects have been found': #TJ use my ONE extra if statement to leave value as nan if there are no objects found\n",
    "            continue\n",
    "        else:\n",
    "            row[\"u_mag\"], row[\"i_mag\"] = float(output.split(',')[2]), float(output.split(',')[5]) #TJ grab the u and i mag values from the output\n",
    "    print(f\"finished sdss query\")\n",
    "    return table\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    '''parser = argparse.ArgumentParser(description=\"\"\"No arguments accepted at command line. Searches 'FIRST' data for objects within 3 degrees \n",
    "    of ra, dec = (163, 50). Cross matches these objects to objects in the legacy north sweep surveys that have W1-W2 colors of > 0.5 AND \n",
    "    r_magnitudes of < 22, then records their g, r, z, and WISE 1-4 nanomaggy flux values and magnitudes. Queries the SDSS database to get \n",
    "    their u and i magnitudes and converts to nanomaggy fluxes. Finds the object in this dataset that is brightest in the u_band and plots\n",
    "    these nine flux values as a function of wavelength. Prints brief comment about results.\"\"\") #TJ add argparse informative help statement\n",
    "    #TJ apparently you need to add at least one argument (even if its useless) to make --help command visible?\n",
    "    parser.add_argument('--dummy', help=argparse.SUPPRESS)  #TJ completely useless, hidden dummy argument\n",
    "    args = parser.parse_args()'''\n",
    "    \n",
    "    #TJ define filepath to FIRST dataset\n",
    "    FIRST_filepath = '/d/scratch/ASTR5160/data/first/first_08jul16.fits'\n",
    "    FIRST_data = read_partial_fits(FIRST_filepath, [\"RA\", \"DEC\"]) #TJ we only need ra and dec from this table.\n",
    "    center_of_field = SkyCoord(163, 50, unit = u.deg) #TJ Define center of field, only objects within 3 degrees of this will be kept\n",
    "    all_obj_loc = SkyCoord(FIRST_data[\"RA\"], FIRST_data[\"DEC\"], unit = u.deg) #TJ create skycoord object for every object in the FIRST file\n",
    "    \n",
    "    in_survey = FIRST_data[all_obj_loc.separation(center_of_field).deg < 3] #TJ extract only objects from the FIRST file that are within 3 degrees\n",
    "    #TJ this can also be done with a search_around_sky(), but for some reason takes longer? idk this timing is inconsistent\n",
    "    #TJ in_survey now is a table of only FIRST objects within the astronomer's survey\n",
    "    \n",
    "    sweep_directory = '/d/scratch/ASTR5160/data/legacysurvey/dr9/north/sweep/9.0/' #TJ assign necessary sweep file directory\n",
    "    #TJ assign needed sweep file paths\n",
    "    sweep_files = search_directory_for_location(sweep_directory, in_survey)\n",
    "    #TJ only save data in columns we actually need, this table has WAYYYY too many columns and it slows down computation time to perform\n",
    "    #TJ manipulations on the entire table.\n",
    "    sweep_columns_to_keep = ['RA', 'DEC', 'FLUX_R', 'FLUX_G', 'FLUX_Z', 'FLUX_W1', 'FLUX_W2', 'FLUX_W3', 'FLUX_W4']\n",
    "    \n",
    "    sweep_data = vstack([read_partial_fits(file, sweep_columns_to_keep) for file in sweep_files]) #TJ stack all the sweep data underneath the last one\n",
    "    for flux_col in ['FLUX_W1', 'FLUX_W2', 'FLUX_R']: #TJ prevent attempting to take log10 of negative number by replacing with a small positive number\n",
    "        #TJ not sure if this is actually faster than an if statement, but its definitely harder to read\n",
    "        sweep_data[flux_col] = np.where(sweep_data[flux_col] <= 0, 1e-10, sweep_data[flux_col]) #TJ is this technically an \"if-else statement\"?\n",
    "    sweep_data = add_mag_column(sweep_data, [\"FLUX_R\", \"FLUX_W1\", \"FLUX_W2\"]) #TJ add magnitude columns for r, W1, and W2\n",
    "\n",
    "    rel_FIRST_data, rel_sweep_data = cross_match(in_survey, sweep_data) #TJ perform cross match using cdk tree matching\n",
    "    #TJ these tables are now only the relevent objects that will be used for further analysis\n",
    "\n",
    "    print(f\"TASK #3 - A total of {len(rel_FIRST_data)} objects were kept for further analysis\") #TJ print total objects that are kept\n",
    "    rel_sweep_data = add_sdss_u_and_i_mag_columns(rel_sweep_data) #TJ query sdss database for each of these objects\n",
    "\n",
    "    nan_count = np.sum(np.isnan(rel_sweep_data['u_mag'])) #TJ count how many nan values are in the set\n",
    "    #TJ the total length, minus number of nans is the number of successful queries from SDSS\n",
    "    \n",
    "    print(f'TASK #5 - SDSS query found magnitudes for {len(rel_sweep_data) - nan_count} of the {len(rel_sweep_data)} objects')\n",
    "    \n",
    "    #TJ I think there is a typo in the assignment and this is actually asking which of these cross-matched objects is the brightest.\n",
    "    #TJ I ran a much more time consuming analysis on all 2637 FIRST objects that are in the astronomer's survey, and it returned\n",
    "    #TJ an object brighter in the u_band. The brightest object is actually sweep_data[2040637] which has a u_mag of 15.07173\n",
    "    #TJ but this object has a W1-W2 color of -0.10889053 which did not meet the minimum value of 0.5 to be selected.\n",
    "    \n",
    "    nan_mask = ~np.isnan(rel_sweep_data[\"u_mag\"]) #TJ mask out the nan(s) in the table so they dont get selected as the lowest value\n",
    "    global_idx = np.where(nan_mask)[0][np.argmin(rel_sweep_data[\"u_mag\"][nan_mask])] #TJ find the index in the full table that has the lowest u_mag\n",
    "    \n",
    "    ubrite1 = {col: rel_sweep_data[col][global_idx] for col in rel_sweep_data.colnames} #TJ create a dictionary that is JUST ubrite1\n",
    "    #TJ I couldnt find a nice way to make a table that is just one row from this table\n",
    "\n",
    "    ubrite1['FLUX_U'] = 10 ** ( -(ubrite1[\"u_mag\"]-22.5)/2.5) #TJ add flux values for u and i bands, sdss query only gave magnitudes\n",
    "    ubrite1['FLUX_I'] = 10 ** ( -(ubrite1[\"i_mag\"]-22.5)/2.5)\n",
    "\n",
    "    #TJ define x,y positions for plotting flux vs wavelength\n",
    "    positions = [[3.543, ubrite1[\"FLUX_U\"]],\n",
    "                 [4.77, ubrite1[\"FLUX_G\"]], \n",
    "                 [6.231, ubrite1[\"FLUX_R\"]], \n",
    "                 [7.625, ubrite1[\"FLUX_I\"]], \n",
    "                 [9.134, ubrite1[\"FLUX_Z\"]], \n",
    "                 [3400, ubrite1[\"FLUX_W1\"]], \n",
    "                 [4600, ubrite1[\"FLUX_W2\"]], \n",
    "                 [12000, ubrite1[\"FLUX_W3\"]],\n",
    "                 [22000, ubrite1[\"FLUX_W4\"]]]                                 \n",
    "    band_labels = ['u', 'g', 'r', 'i', 'z', 'W1', 'W2', 'W3', 'W4'] #TJ these will be the labels for the datapoints on the graph\n",
    "    wavelengths = np.array([p[0] for p in positions]) #TJ pick out wavelengths and fluxes\n",
    "    fluxes = np.array([p[1] for p in positions])\n",
    "    \n",
    "    plt.plot(wavelengths, fluxes, '-', color='red', linewidth=1) #TJ plot a line connecting each flux measurement\n",
    "    plt.scatter(wavelengths, fluxes, s=10, color='black') #TJ put dots on the actual data points\n",
    "    for w, f, label in zip(wavelengths, fluxes, band_labels):\n",
    "        plt.text(w, f*1.1, label, ha='center', va='bottom', fontsize=9) #TJ label all the dots with their respective band labels\n",
    "    plt.xscale('log') #TJ change x-axis to log space so the ugriz arent on top of each other\n",
    "    plt.yscale('log') #TJ change y-axis to log space so the ugriz arent all just at basically zero compared to WISE bands\n",
    "    plt.xlabel('Wavelength\\n(in microns)')\n",
    "    plt.ylabel('Flux\\n(in nanomaggies)')\n",
    "    plt.title('Low Resolution Spectral Energy Distribution for ubrite1')\n",
    "    plt.show()    \n",
    "    print('TASK #10 -')\n",
    "    print('''\\tThis object is classified as a STAR, but is at redshift of 1.03, which is not in our galaxy. It's spectrum is labeled as a QSO \n",
    "    which makes much more sense. This object was selected because it has a large flux in the u-band, and its W2 flux is significantly\n",
    "    larger than its W1 flux (this comes from the constraint that W1-W2 > 0.5, which traces hot dust emission). Coupled with the fact that\n",
    "    we masked out all objects with low r_band emission, it is not surprising that this optically bright object that is surrounded \n",
    "    by hot dust happens to be an extragalactic QSO''')\n",
    "    \n",
    "    #TJ print total time for script for execution\n",
    "    print() #TJ adding lines to separate printed statements\n",
    "    print()\n",
    "    print()\n",
    "    print(f\"Script finished in {time.time() - start:.2f} seconds\")\n",
    "    print()\n",
    "    print('After re-running this script from scratch a bunch of times, the median time (in seconds) was 73, with a mean of 146 \\nand a standard deviation of 115. Note that this distribution is heavily skewed to longer runtimes and no trial took LESS than 70 seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
